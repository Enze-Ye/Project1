import argparse, csv, math, os, random
from typing import Dict, Tuple, List

# Alphabet used for search (bytes we try to place into p1)
ALPHABET: bytes = b" ABCDEFGHIJKLMNOPQRSTUVWXYZ"

# Small common-word bonus (uppercased, modest weight)
COMMON_WORDS = {
    "THE","AND","YOU","THAT","WAS","THIS","WITH","FOR","HAVE","NOT",
    "ARE","BUT","HAD","THEY","HIS","FROM","SHE","WHICH","WILL","ONE"
}

# Map a byte to scoring symbol and a small penalty
def b2sym(b: int) -> Tuple[str, float]:
    if b == 32:  # space
        return " ", 0.0
    if 65 <= b <= 90:  # 'A'..'Z'
        return chr(b), 0.0
    if 97 <= b <= 122:  # 'a'..'z' -> uppercase
        return chr(b - 32), 0.0
    return " ", -1.0  # other bytes treated as space with penalty

# XOR helper
def bxor(a: bytes, b: bytes) -> bytes:
    return bytes([x ^ y for x, y in zip(a, b)])

# Read 2048-byte input and split
def read_ct_pair(path: str, k: int = 1024) -> Tuple[bytes, bytes]:
    data = open(path, "rb").read()
    if len(data) != 2 * k:
        raise ValueError(f"expected {2*k} bytes, got {len(data)}")
    return data[:k], data[k:]

# Load ftable2.csv -> (unigram logP, bigram logP) with smoothing
def load_lm(ftable_csv: str) -> Tuple[Dict[str, float], Dict[Tuple[str, str], float], List[str]]:
    rows = list(csv.reader(open(ftable_csv, newline="", encoding="utf-8", errors="replace")))
    header = rows[0][1:]  # symbols (space, A..Z)
    # raw bigram counts
    counts: Dict[Tuple[str, str], float] = {}
    for r in rows[1:]:
        if not r: 
            continue
        a = (r[0] or " ").strip() or " "
        for i, cell in enumerate(r[1:]):
            try:
                v = float(cell)
            except:
                v = 0.0
            counts[(a, header[i])] = v
    # row sums
    row_sum: Dict[str, float] = {}
    for (a, b), v in counts.items():
        row_sum[a] = row_sum.get(a, 0.0) + v
    # bigram logP with Laplace(+1)
    K = len(header)
    log_big: Dict[Tuple[str, str], float] = {}
    for (a, b), v in counts.items():
        tot = row_sum.get(a, 0.0)
        p = (v + 1.0) / (tot + K) if tot > 0 else 1.0 / K
        log_big[(a, b)] = math.log(p)
    # unigram from column sums (with +1 smoothing)
    col = {b: 1.0 for b in header}
    for (a, b), v in counts.items():
        col[b] = col.get(b, 0.0) + v
    totu = sum(col.values())
    log_uni = {b: math.log(col[b] / totu) for b in header}
    return log_uni, log_big, header

# Score one sequence with LM (unigram start + bigrams + penalties)
def score_seq(bs: bytes, log_uni: Dict[str, float], log_big: Dict[Tuple[str, str], float]) -> float:
    if not bs:
        return -1e18
    c0, p0 = b2sym(bs[0])
    s = log_uni.get(c0, math.log(1e-9)) + p0
    for i in range(1, len(bs)):
        a, pa = b2sym(bs[i - 1])
        b, pb = b2sym(bs[i])
        s += log_big.get((a, b), math.log(1e-9)) + pb
    return s

# Small word bonus to gently encourage common words
def word_bonus(bs: bytes) -> float:
    toks = bytes(bs).decode("utf-8", "ignore").upper().split()
    hit = sum(1 for t in toks if t in COMMON_WORDS)
    return 0.3 * hit

# Combined objective for p1 and implied p2
def total_obj(p1: bytes, X: bytes, log_uni, log_big) -> float:
    p2 = bxor(p1, X)
    return score_seq(p1, log_uni, log_big) + score_seq(p2, log_uni, log_big) + word_bonus(p1) + word_bonus(p2)

# Greedy unigram initializer for p1
def init_p1_unigram(X: bytes, log_uni: Dict[str, float]) -> bytearray:
    k = len(X)
    p1 = bytearray(k)
    for i, xi in enumerate(X):
        best_b, best = 32, -1e18
        for b in ALPHABET:
            c1, _ = b2sym(b)
            c2, _ = b2sym(b ^ xi)
            sc = log_uni.get(c1, math.log(1e-9)) + log_uni.get(c2, math.log(1e-9))
            if sc > best:
                best, best_b = sc, b
        p1[i] = best_b
    return p1

# Letter/space heuristic: if x[i] looks like letter after mapping, prefer one side space
def letter_hint(xb: int) -> bool:
    ch, _ = b2sym(xb)
    return ch != " "

# Hill-climb with annealed acceptance and structure hints
def search(X: bytes, log_uni, log_big, restarts: int, iters: int) -> Tuple[bytes, bytes]:
    k = len(X)
    best_p1, best_val = b"", -1e18
    for _ in range(restarts):
        p1 = init_p1_unigram(X, log_uni)
        cur = total_obj(p1, X, log_uni, log_big)
        for it in range(iters):
            i = random.randrange(k)
            xi = X[i]
            # candidate set with hint
            if letter_hint(xi):
                cand = [32] + [b for b in ALPHABET if b2sym(b ^ xi)[0] == " "]
            else:
                cand = list(ALPHABET)
            old = p1[i]
            nb = random.choice(cand)
            if nb == old:
                continue
            p1[i] = nb
            new = total_obj(p1, X, log_uni, log_big)
            d = new - cur
            T = max(0.02, 1.0 - it / iters)
            if d >= 0 or random.random() < math.exp(d / T):
                cur = new
                if cur > best_val:
                    best_val = cur
                    best_p1 = bytes(p1)
            else:
                p1[i] = old
    p2 = bxor(best_p1, X)
    return best_p1, p2

# CLI wrapper: read inputs, run search, write outputs
def main():
    ap = argparse.ArgumentParser(description="Two-time pad solver (English-only, LM + annealed search).")
    ap.add_argument("ct_bin")
    ap.add_argument("ftable_csv")
    ap.add_argument("--restarts", type=int, default=8)
    ap.add_argument("--iters", type=int, default=250000)
    ap.add_argument("--k", type=int, default=1024)
    ap.add_argument("--seed", type=int, default=0)
    args = ap.parse_args()

    if args.seed:
        random.seed(args.seed)

    c1, c2 = read_ct_pair(args.ct_bin, k=args.k)
    X = bxor(c1, c2)
    log_uni, log_big, _ = load_lm(args.ftable_csv)

    p1, p2 = search(X, log_uni, log_big, restarts=args.restarts, iters=args.iters)

    open("plain1.txt", "wb").write(p1)
    open("plain2.txt", "wb").write(p2)
    pad = bxor(c1, p1)
    open("pad.bin", "wb").write(pad)
    print("[+] wrote plain1.txt, plain2.txt, pad.bin")

if __name__ == "__main__":
    main()
